{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11sd-YWR2pH4xe4xBX5gVAd4FHAiKLJV1",
      "authorship_tag": "ABX9TyNH4gggXZk7DYfnQB6g7cQM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joy-Onuoha21/Machine-Learning-Project/blob/main/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHw4PlF0Gx1s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "trainData = pd.read_csv(\"train.data\", header = None)\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_data(data, class_list):\n",
        "    filtered_data = data[(data.iloc[:, -1] == class_list[0]) | (data.iloc[:, -1] == class_list[1])]\n",
        "    dataset = np.array(filtered_data)\n",
        "    dataset[:,-1][dataset[:,-1] == class_list[0]] = 1\n",
        "    dataset[:,-1][dataset[:,-1] == class_list[1]] = -1\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# filtering classes\n",
        "filter_classes_1or2 = preprocess_data(trainData, ['class-1', 'class-2'])\n",
        "filter_classes_1or3 = preprocess_data(trainData, ['class-1', 'class-3'])\n",
        "filter_classes_2or3 = preprocess_data(trainData, ['class-2', 'class-3'])\n",
        "\n",
        "def PerceptronTrain(dataset, MaxIter):\n",
        "    # Initialize weights and bias to zero\n",
        "    weights = np.zeros((dataset.shape[1] - 1, 1))\n",
        "    bias = 0\n",
        "\n",
        "    # Iterate for a maximum of max_iter epochs\n",
        "    for epoch in range(20):\n",
        "        # Iterate over each data point in the data\n",
        "        for i in range(dataset.shape[0]):\n",
        "            # Extract the input features and target label\n",
        "            input_features = dataset[i, :-1].reshape(-1, 1)\n",
        "            target_label  = dataset[i, -1]\n",
        "\n",
        "            # Compute the predicted output of the perceptron\n",
        "            activation = np.dot(weights.T, input_features) + bias\n",
        "\n",
        "            # Update the weights and bias if the predicted output is incorrect\n",
        "            if target_label * activation <= 0:\n",
        "                weights = weights + (target_label * input_features)\n",
        "                bias += target_label\n",
        "    return bias, weights\n",
        "\n",
        "bias1or2, weights1or2 = PerceptronTrain(filter_classes_1or2,20)\n",
        "bias1or3, weights1or3 = PerceptronTrain(filter_classes_1or3,20)\n",
        "bias2or3, weights2or3 =PerceptronTrain(filter_classes_2or3,20)\n",
        "\n",
        "\n",
        "\n",
        "testData = pd.read_csv(\"test.data\", header = None)\n",
        "\n",
        "filterTest_classes_1or2 = preprocess_data(testData, ['class-1', 'class-2'])\n",
        "filterTest_classes_1or3 = preprocess_data(testData, ['class-1', 'class-3'])\n",
        "filterTest_classes_2or3 = preprocess_data(testData, ['class-2', 'class-3'])\n",
        "\n",
        "def sign(x):\n",
        "    return 1 if x >= 0 else -1\n",
        "\n",
        "def PerceptronTest(dataset, weights, bias):\n",
        "\n",
        "    # Extract the input features and target labels\n",
        "    input_features = dataset[:, :-1]\n",
        "    target_label = dataset[:, -1]\n",
        "\n",
        "    # Compute the predicted labels for the test data\n",
        "    predicted_labels = np.sign(np.dot(input_features, weights) + bias).flatten()\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "def accuracy(dataset, predicted_labels):\n",
        "\n",
        "    target_label = dataset[:, -1]\n",
        "\n",
        "    positive_mask = target_label == 1\n",
        "\n",
        "    # Compute the number of true positive, true negative, false positive, and false negative\n",
        "    tp = np.sum((target_label == 1) & (predicted_labels == 1))\n",
        "    tn = np.sum((target_label == -1) & (predicted_labels == -1))\n",
        "    fp = np.sum((target_label == -1) & (predicted_labels == 1))\n",
        "    fn = np.sum((target_label == 1) & (predicted_labels == -1))\n",
        "\n",
        "    # Compute the accuracy\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "y_pred_trainData10r2 = PerceptronTest(filter_classes_1or2, weights1or2, bias1or2)\n",
        "y_pred_trainData10r3 = PerceptronTest(filter_classes_1or3, weights1or3, bias1or3)\n",
        "y_pred_trainData20r3 = PerceptronTest(filter_classes_2or3, weights2or3, bias2or3)\n",
        "\n",
        "y_pred_testData10r2 = PerceptronTest(filterTest_classes_1or2, weights1or2, bias1or2)\n",
        "y_pred_testData10r3 = PerceptronTest(filterTest_classes_1or3, weights1or3, bias1or3)\n",
        "y_pred_testData20r3 = PerceptronTest(filterTest_classes_2or3, weights2or3, bias2or3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy_trainData10r2 = print(\"accuracy_trainData10r2: \", accuracy(filter_classes_1or2, y_pred_trainData10r2))\n",
        "accuracy_trainData10r3 = print(\"accuracy_trainData10r3: \", accuracy(filter_classes_1or3, y_pred_trainData10r3))\n",
        "accuracy_trainData20r3 = print(\"accuracy_trainData20r3: \", accuracy(filter_classes_2or3, y_pred_trainData20r3))\n",
        "\n",
        "accuracy_testData10r2 = print(\"accuracy_testData10r2: \", accuracy(filterTest_classes_1or2, y_pred_testData10r2))\n",
        "accuracy_testData10r3 = print(\"accuracy_testData10r3: \", accuracy(filterTest_classes_1or3, y_pred_testData10r3))\n",
        "accuracy_testData20r3 = print(\"accuracy_testData20r3: \", accuracy(filterTest_classes_2or3, y_pred_testData20r3))\n",
        "\n",
        "\n",
        "# Funtion to separate the 1 vs the rest\n",
        "def preprocess_data(data, interest_class):\n",
        "    filtered_data = data[(data.iloc[:, -1] == interest_class) | (data.iloc[:, -1] != interest_class)]\n",
        "    dataset = np.array(filtered_data)\n",
        "    dataset[:,-1][dataset[:,-1] == interest_class] = 1\n",
        "    dataset[:,-1][dataset[:,-1] != 1] = -1\n",
        "    return dataset\n",
        "\n",
        "# Filtering classes\n",
        "filtertest_classes_1andRest = preprocess_data(testData, \"class-1\")\n",
        "filtertest_classes_2andRest = preprocess_data(testData, \"class-2\")\n",
        "filtertest_classes_3andRest = preprocess_data(testData, \"class-3\")\n",
        "\n",
        "filtertrain_classes_1andRest = preprocess_data(trainData, \"class-1\")\n",
        "filtertrain_classes_2andRest = preprocess_data(trainData, \"class-2\")\n",
        "filtertrain_classes_3andRest = preprocess_data(trainData, \"class-3\")\n",
        "\n",
        "# Variable assignment to weight and bias\n",
        "multi_b1andRest, Multi_w1andRest = PerceptronTrain(filtertrain_classes_1andRest,20)\n",
        "multi_b2andRest, Multi_w2andRest = PerceptronTrain(filtertrain_classes_2andRest,20)\n",
        "multi_b3andRest, Multi_w3andRest = PerceptronTrain(filtertrain_classes_3andRest,20)\n",
        "\n",
        "\n",
        "\n",
        "def PredictMulticlass(classifier1, classifer2, classifer3, input_fea):\n",
        "    \"\"\"\n",
        "    Function to predict class label of a dataset using 1-vs-rest approach.\n",
        "\n",
        "    Parameters:\n",
        "        classifier1 (tuple): Bias and weights for class 1.\n",
        "        classifer2 (tuple): Bias and weights for class 2.\n",
        "        classifer3 (tuple): Bias and weights for class 3.\n",
        "        input_features (numpy.ndarray): Dataset with d number of features.\n",
        "\n",
        "    Returns:\n",
        "        y_Pred (numpy.ndarray): Array of predicted class labels ordered according to records in input_features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the number of features\n",
        "    d = input_fea.shape[1]\n",
        "\n",
        "    # Initialize array to store predicted class labels\n",
        "    y_Pred = np.empty(input_fea.shape[0], dtype=int)\n",
        "\n",
        "    # Iterate over each record in Xset\n",
        "    for i in range(input_fea.shape[0]):\n",
        "        # Get the i-th record\n",
        "        X = input_fea[i, :-1].reshape(-1, 1)\n",
        "\n",
        "        # Get the activation scores for each class\n",
        "        score1 = np.dot(classifier1[1].T, X) + classifier1[0]\n",
        "        score2 = np.dot(classifer2[1].T, X) + classifer2[0]\n",
        "        score3 = np.dot(classifer3[1].T, X) + classifer3[0]\n",
        "\n",
        "\n",
        "        # Choose the label with the highest activation score\n",
        "        if score1 >= score2 and score1 >= score3:\n",
        "            y_Pred[i] = 1\n",
        "        elif score2 >= score1 and score2 >= score3:\n",
        "            y_Pred[i] = 2\n",
        "        else:\n",
        "            y_Pred[i] = 3\n",
        "\n",
        "    return y_Pred\n",
        "\n",
        "datatrain = np.array(trainData.iloc[:, 0:5])\n",
        "\n",
        "\n",
        "\n",
        "#for train data\n",
        "label_map = {'class-1': 1, 'class-2': 2, 'class-3': 3}\n",
        "\n",
        "\n",
        "# Extract labels from the data\n",
        "labels = trainData.iloc[:, -1]\n",
        "\n",
        "# Map the labels to classes using the label_map\n",
        "classes = np.array([label_map[label] for label in labels])\n",
        "\n",
        "# Print the transformed data\n",
        "multidataset = np.hstack((trainData.iloc[:, :-1], classes.reshape(-1, 1)))\n",
        "\n",
        "\n",
        "\n",
        "def accuracyMulticlass(dataset, y_Pred):\n",
        "\n",
        "  target_label = dataset[:, -1]\n",
        "\n",
        "  acc = np.mean(y_Pred==target_label)\n",
        "\n",
        "  return acc\n",
        "\n",
        "y_pred_Multiclasstrain = PredictMulticlass((multi_b1andRest, Multi_w1andRest ), (multi_b2andRest, Multi_w2andRest), (multi_b3andRest, Multi_w3andRest), datatrain)\n",
        "\n",
        "multiAccuracytrain = print(\"accuracyMulticlass for train: \", accuracyMulticlass(multidataset, y_pred_Multiclasstrain))\n",
        "\n",
        "#for test data\n",
        "label_map = {'class-1': 1, 'class-2': 2, 'class-3': 3}\n",
        "\n",
        "datatest = np.array(testData.iloc[:, 0:5])\n",
        "\n",
        "# Extract labels from the data\n",
        "labels = testData.iloc[:, -1]\n",
        "\n",
        "# Map the labels to classes using the label_map\n",
        "classes = np.array([label_map[label] for label in labels])\n",
        "\n",
        "# Print the transformed data\n",
        "multidataset_test = np.hstack((testData.iloc[:, :-1], classes.reshape(-1, 1)))\n",
        "\n",
        "\n",
        "\n",
        "y_pred_Multiclasstest = PredictMulticlass((multi_b1andRest, Multi_w1andRest ), (multi_b2andRest, Multi_w2andRest), (multi_b3andRest, Multi_w3andRest), datatest)\n",
        "\n",
        "multiAccuracytest = print(\"accuracyMulticlass for test: \", accuracyMulticlass(multidataset_test, y_pred_Multiclasstest))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def PerceptronTrainCo(dataset, MaxIter, Coff):\n",
        "    # Initialize weights and bias to zero\n",
        "    weights = np.zeros((dataset.shape[1] - 1, 1))\n",
        "    bias = 0\n",
        "    # Iterate for a maximum of max_iter epochs\n",
        "    for epoch in range(20):\n",
        "        # Iterate over each data point in the shuffled data\n",
        "        for i in range(dataset.shape[0]):\n",
        "            # Extract the input features and target label\n",
        "            input_features = dataset[i, :-1].reshape(-1, 1)\n",
        "            target_label  = dataset[i, -1]\n",
        "\n",
        "            # Compute the predicted output of the perceptron\n",
        "            activation = np.dot(weights.T, input_features) + bias\n",
        "\n",
        "            # Update the weights and bias if the predicted output is incorrect\n",
        "            if target_label * activation <= 0:\n",
        "                weights = (1 - 2 * Coff) * weights + (target_label * input_features)\n",
        "                bias += target_label\n",
        "            else:\n",
        "                weights = weights * (1 - 2 * Coff)\n",
        "                bias = bias\n",
        "    return bias, weights\n",
        "\n",
        "\n",
        "Coff_values = [.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "for Coff in Coff_values:\n",
        "\n",
        "  # Train data with L2 regularisation Coefficient\n",
        "  multi_b1andRest, Multi_w1andRest = PerceptronTrainCo(filtertrain_classes_1andRest,20,Coff)\n",
        "  multi_b2andRest, Multi_w2andRest = PerceptronTrainCo(filtertrain_classes_2andRest,20,Coff)\n",
        "  multi_b3andRest, Multi_w3andRest = PerceptronTrainCo(filtertrain_classes_3andRest,20,Coff)\n",
        "\n",
        "  y_pred_Multiclasstrain = PredictMulticlass((multi_b1andRest, Multi_w1andRest ), (multi_b2andRest, Multi_w2andRest), (multi_b3andRest, Multi_w3andRest), datatrain)\n",
        "\n",
        "  multiAccuracytrain = print(\"accuracyMulticlass for train: \", accuracyMulticlass(multidataset, y_pred_Multiclasstrain), \"Coff:\", Coff)\n",
        "  y_pred_Multiclasstest = PredictMulticlass((multi_b1andRest, Multi_w1andRest ), (multi_b2andRest, Multi_w2andRest), (multi_b3andRest, Multi_w3andRest), datatest)\n",
        "\n",
        "  multiAccuracytrain = print(\"accuracyMulticlass for test: \", accuracyMulticlass(multidataset_test, y_pred_Multiclasstest), \"Coff:\", Coff)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}